{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZQsIP7OBg3c"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je5e8oH_DLSV"
      },
      "source": [
        "Named Entity Recognition (NER) is a natural language processing (NLP) technique used to identify and classify key information (entities) in text into predefined categories such as names of people, organizations, locations, dates, and more. In our project, we apply NER for spatial tagging—extracting spatially relevant terms from policy documents to support geographic analysis and planning.\n",
        "\n",
        "We selected NER as our primary approach because many existing NER frameworks already provide built-in support for recognizing geographical entities such as cities, countries, and locations. From this base, we can extend the models by adding domain-specific entities relevant to planning and zoning, making NER a natural fit for our spatial text analysis needs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHPuiAwhDOtm"
      },
      "source": [
        "For a comprehensive overview of NER, see this resource: A Comprehensive Guide to Named Entity Recognition. https://www.turing.com/kb/a-comprehensive-guide-to-named-entity-recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Ichm5IEHrm"
      },
      "source": [
        "We experimented with multiple NLP libraries to implement NER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEDS2uZpEI3U"
      },
      "source": [
        "# spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "246IyxVET5gL"
      },
      "source": [
        "## *Built-In Model*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHGdmKkaT7_j"
      },
      "source": [
        "We first tested spaCy’s built-in NER model to evaluate its baseline performance on our documents.\n",
        "\n",
        "Here are what spaCy’s NER entities offer:\n",
        "\n",
        "`CARDINAL`, `DATE`, `EVENT`, `FAC`, `GPE`, `LANGUAGE`, `LAW`, `LOC`, `MONEY`, `NORP`, `ORDINAL`, `ORG`, `PERCENT`, `PERSON`, `PRODUCT`, `QUANTITY`, `TIME`, `WORK_OF_ART`\n",
        "\n",
        "[more detail here](https://spacy.io/models/en)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmN40v-_VomL"
      },
      "source": [
        "From spaCy’s recognized entity types, we focused on those relevant to spatial tagging:\n",
        "* `GPE` (Geo-Political Entity): Cities, countries, regions\n",
        "* `LOC` (Location): Non-political locations such as mountains or bodies of water\n",
        "* `ORG` (Organization): Named businesses, agencies, and institutions\n",
        "* `FAC` (Facility): Physical structures, buildings, and infrastructure\n",
        "* MISC (Miscellaneous): Other entities that may not fit above categories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeeMnKioWW94"
      },
      "source": [
        "### Implementation Steps\n",
        "\n",
        "1. Import necessary libraries\n",
        "2. Load extracted policy documents\n",
        "3. Load spaCy pretrained NER model\n",
        "4. Process texts to extract entities\n",
        "5. Save to CSV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foKxengwc1xp"
      },
      "source": [
        "#### Step 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwuqH7LlT7Dx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU_FJPvhdfCc"
      },
      "source": [
        "We import the necessary libraries:\n",
        "\n",
        "* `pandas` for handling tabular data\n",
        "* `spacy` for performing Named Entity Recognition (NER)\n",
        "* `csv` for writing output data to a CSV file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFYnXRtzdkkM"
      },
      "source": [
        "#### Step 2: Load Input Data and Pre-trained NER Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdyW8JDxb1Kq"
      },
      "outputs": [],
      "source": [
        "policies_df = pd.read_csv('napa_policies_cleaned.csv') # load in csv of napa gp policies\n",
        "ner = spacy.load('en_core_web_sm') # load pre-trained NER model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWpOLLnXdq_o"
      },
      "source": [
        "* Load the Napa policy data from a cleaned CSV file into a Pandas DataFrame.\n",
        "\n",
        "* Load spaCy’s **pre-trained English NER model** (en_core_web_sm) for entity extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_zCi6FId0Hw"
      },
      "source": [
        "#### Step 3: Define NER Extraction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gufFAi7Wb8tW"
      },
      "outputs": [],
      "source": [
        "def extract_ner(policies):\n",
        "\n",
        "    doc = ner(policies) # process NER\n",
        "\n",
        "    # entity dictionary\n",
        "    entities = {\n",
        "        \"GPE\": [], # geo-political\n",
        "        \"LOC\": [], # locations\n",
        "        \"ORG\": [], # organizations\n",
        "        \"FAC\": [], # facilities\n",
        "        \"MISC\": []\n",
        "    }\n",
        "\n",
        "    # loop thru entities\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"GPE\":\n",
        "            entities[\"GPE\"].append(ent.text)\n",
        "        elif ent.label_ == \"LOC\":\n",
        "            entities[\"LOC\"].append(ent.text)\n",
        "        elif ent.label_ == \"ORG\":\n",
        "            entities[\"ORG\"].append(ent.text)\n",
        "        elif ent.label_ == \"FAC\":\n",
        "            entities[\"FAC\"].append(ent.text)\n",
        "\n",
        "    # return policy & entities\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCCgdG5BeBsQ"
      },
      "source": [
        "This function:\n",
        "\n",
        "* Takes a policy (string) as input.\n",
        "\n",
        "* Uses spaCy to extract named entities from the text.\n",
        "\n",
        "* Filters for entity types we care about:\n",
        "\n",
        "  * `GPE`: Geopolitical entities (cities, countries, states)\n",
        "  * `LOC`: Locations (non-political, like \"the river\")\n",
        "  * `ORG`: Organizations (agencies, companies)\n",
        "  * `FAC`: Facilities (buildings, infrastructure)\n",
        "  * `MISC`: Placeholder if needed for unexpected entities\n",
        "\n",
        "* Returns a dictionary of extracted entities for each category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo_HGX_ueXiS"
      },
      "source": [
        "#### Step 4: Apply NER Function to Each Policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOBS73kLekyd"
      },
      "outputs": [],
      "source": [
        "data = policies_df['Policy'].apply(extract_ner) # apply function to each policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fElvGDV0ehPC"
      },
      "source": [
        "#### Step 5: Save Results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0nuV38ienMl"
      },
      "outputs": [],
      "source": [
        "# extract entities from policies\n",
        "\n",
        "# Prepare the CSV file name\n",
        "policies_csv = 'napa_policies_entities.csv'\n",
        "\n",
        "# Open the file for writing\n",
        "with open(policies_csv, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row: Column names for entity types\n",
        "    header = ['Policy', 'GPE', 'LOC', 'ORG', 'FAC', 'MISC']\n",
        "    writer.writerow(header)\n",
        "\n",
        "    # Write each row of data\n",
        "    for policy, entities in zip(policies_df['Policy'], data):\n",
        "        row = [\n",
        "            policy,\n",
        "            ', '.join(entities['GPE']),  # Join entity lists into a single string\n",
        "            ', '.join(entities['LOC']),\n",
        "            ', '.join(entities['ORG']),\n",
        "            ', '.join(entities['FAC']),\n",
        "            ', '.join(entities['MISC'])\n",
        "        ]\n",
        "        writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty_lpuVget2D"
      },
      "source": [
        "The output file napa_policies_entities.csv will contain one row per policy, with separate columns showing the extracted named entities under each category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4IBqbNGbzPh"
      },
      "source": [
        "The built-in spaCy model identified many relevant spatial entities but missed domain-specific spatial terms like zoning classifications, land use types, area measurements, and housing categories, which are critical for our analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBLbHnq7fBu-"
      },
      "source": [
        "## *Custom Model*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-ZXeE0KfPK1"
      },
      "source": [
        "To better capture domain-specific spatial terms, we created a custom NER model by extending entity types and manually labeling a dataset that was tailored for us.\n",
        "\n",
        "So, we decided to add these entities:\n",
        "* `AGRICULTURE`: Agricultural areas, practices, or terms\n",
        "* `RESIDENTIAL`: Residential designations, zones, or related terms\n",
        "* `OPEN_SPACE`: Parks, undeveloped land, or designated open space\n",
        "* `ZONING`: Zoning classifications or codes\n",
        "* `LANDUSE`: General land use categories (e.g., agricultural, residential, industrial)\n",
        "* `FACILITY_STATUS`: Operational or functional status of facilities\n",
        "* `HOUSING`: Terms related to housing types, development, or density\n",
        "* `MAP_SOURCE`: References to maps, planning diagrams, or cartographic sources\n",
        "* `PLANNING_AREA`: Named districts, planning zones, or defined geographic units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SRGxBqcfffX"
      },
      "source": [
        "### Dataset Preparation\n",
        "\n",
        "We built a custom labeled dataset using:\n",
        "* Primary source: We used extracted scorecard policies, many of which already included underlined terms that pointed to potentially relevant spatial references.\n",
        "* Limitations: While these underlined elements provided a helpful starting point, the markup was inconsistent and not always reliable, requiring further refinement.\n",
        "* Manual annotation: To address this, we manually labeled additional entities across the dataset to ensure coverage of the new spatial categories. This step significantly improved entity recognition quality and consistency.\n",
        "\n",
        "The initial version of the dataset focuses on agricultural-related content, allowing us to evaluate model performance in a specific and controlled domain before expanding to broader planning topics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VxJdFADfo9a"
      },
      "source": [
        "Here is the dataset as a JSON file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G3WNfHWfp5H"
      },
      "outputs": [],
      "source": [
        "{\n",
        "    \"training_data\": [\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-1: Agriculture and related activities are the primary land uses in Napa County\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 16, \"end\": 50, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 77, \"end\": 91, \"label\": \"GEO\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-3: The County’s planning concepts and zoning standards shall be designed to minimize conflicts arising from encroachment of urban uses into agricultural areas. Land in proximity to existing urbanized areas currently in mixed agricultural and rural residential uses will be treated as buffer areas and further parcelization of these areas will be discouraged.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 119, \"end\": 131, \"label\": \"RESIDENTIAL\" },\n",
        "          { \"start\": 137, \"end\": 156, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 173, \"end\": 204, \"label\": \"RESIDENTIAL\" },\n",
        "          { \"start\": 218, \"end\": 242, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 247, \"end\": 271, \"label\": \"RESIDENTIAL\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-4: The County will reserve agricultural lands for agricultural use including lands used for grazing and watershed/open space, except for those lands which are shown on the Land Use Map as planned for urban development.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 33, \"end\": 52, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 57, \"end\": 77, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 96, \"end\": 111, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 116, \"end\": 138, \"label\": \"OPEN_SPACE\" },\n",
        "          { \"start\": 199, \"end\": 217, \"label\": \"RESIDENTIAL\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-7: The County will research, evaluate, and pursue new approaches to ensure ever stronger protections for the County’s finite and irreplaceable agricultural resources. Approaches to be evaluated shall include implementation of a “Super Williamson Act” program, a conservation easement program or other permanent protections, and programs promoting the economic viability of agriculture.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 118, \"end\": 178, \"label\": \"AGRICULTURE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-8: The County’s minimum agricultural parcel sizes shall ensure that agricultural areas can be maintained as economic units.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 32, \"end\": 54, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 81, \"end\": 99, \"label\": \"AGRICULTURE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-9: The County shall evaluate discretionary development projects, re-zonings, and public projects to determine their potential for impacts on farmlands mapped by the State Farmland Mapping and Monitoring Program, while recognizing that the state’s farmland terminology and definitions are not always the most relevant to Napa County, and shall avoid converting farmland where feasible. Where conversion of farmlands mapped by the state cannot be avoided, the County shall require long-term preservation of one acre of existing farm land of equal or higher quality for each acre of state-designated farmland that would be converted to nonagricultural uses. This protection may consist of establishment of farmland easements or other similar mechanism, and the farmland to be preserved shall be located within the County and preserved prior to the proposed conversion. The County shall recommend this measure for implementation by the cities and town and LAFCO as part of annexations involving state-designated farmlands.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 17, \"end\": 56, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 83, \"end\": 112, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 116, \"end\": 134, \"label\": \"AGRICULTURE\" },\n",
        "          { \"start\": 154, \"end\": 223, \"label\": \"AGRICULTURE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-10: New wineries and other agricultural processing facilities as well as expansions of existing wineries and facilities in agricultural areas should be designed to convey their permanence and attractiveness.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 17, \"end\": 154, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-11: Agricultural employee housing shall be permitted in agricultural zoning districts in conformance with state law. Seasonal farm labor housing may be provided in agricultural areas without regard to the location of farm employment in Napa County when the housing is under local public agency ownership or control.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 69, \"end\": 88, \"label\": \"ZONING\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-13: The 1990 Winery Definition Ordinance, recognized certain pre-existing wineries and winery uses as well as new wineries. For wineries approved after the effective date of that ordinance, agricultural processing includes tours and tastings by appointment only, retail sales of wine produced by or for the winery partially or totally from Napa County grapes, retail sale of wine-related items, activities for the education and development of consumers and members of the wine trade with respect to wine produced by or at the winery, and limited non-commercial food service. The later activity may include winefood pairings. All tours and tastings, retail sales, marketing activities, and noncommercial food service must be accessory to the principal use of the facility as an agricultural processing facility. Nothing in this policy shall alter the definition of “agriculture” set forth in Policy AG/LU-2\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 141, \"end\": 201, \"label\": \"FACILITY_STATUS\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-14: The same location, design, and other considerations applied to wineries shall apply to all other food processing businesses or industrial uses located in agricultural areas.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 104, \"end\": 189, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-17: The County encourages active, sustainable forest management practices, including timely harvesting to preserve existing forests, retaining their health, product, and value. The County also encourages timber plantations for fuel wood and lumber production. (For more policies related to the managed production of resources and forest management practices, please see the Conservation Element.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 128, \"end\": 144, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-18: Timber production areas in the County shall be considered to be those defined in the most recent adopted mapping available from CAL FIRE unless local areas are defined through a public planning process.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 102, \"end\": 148, \"label\": \"MAP_SOURCE\" },\n",
        "          { \"start\": 161, \"end\": 184, \"label\": \"PLANNING_AREA\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-20: The following standards shall apply to lands designated as Agriculture, Watershed, and Open Space on the Land Use Map of this General Plan. Intent: To provide areas where the predominant use is agriculturally oriented; where watersheds are protected and enhanced; where reservoirs, floodplain tributaries, geologic hazards, soil conditions, and other constraints make the land relatively unsuitable for urban development; where urban development would adversely impact all such uses; and where the protection of agriculture, watersheds, and floodplain tributaries from fire, pollution, and erosion is essential to the general health, safety, and welfare. General Uses: Agriculture, processing of agricultural products, single-family dwellings. Minimum Parcel Size: 160 acres, except that parcels with a minimum size of 2 acres may be created for the sole purpose of developing farm labor camps by a local government agency authorized to own or operate farm labor camps, so long as the division is accomplished by securing the written consent of a local government agency authorized to own or operate farm labor camps that it will accept a conveyance of the fee interest of the parcel to be created and thereafter conveying the fee interest of such parcel directly to said local government agency, or entering into a long-term lease of such parcels directly with said local government agency, or entering into a long-term lease of such parcels directly with said local government agency. Every lease or deed creating such parcels must contain language ensuring that if the parcel is not used as a farm labor camp within three years of the conveyance or lease being executed or permanently ceases to be used as a farm labor camp by a local government agency authorized to develop farm labor camps, the parcel will automatically revert to, and merge into, the original parent parcel. Maximum Building Intensity: One dwelling per parcel (except as specified in the Housing Element). Nonresidential building intensity is non-applicable. Pursuant to Measure Z (1996), the sale to the public of agricultural produce, fruits, vegetables, and Christmas trees, grown on or off premises, and items related thereto, as well as the recreation and educational uses by children of animals, such as children’s pony rides and petting zoos, and construction of buildings to accommodate such sales and animals shall be permitted on any parcel designated as agricultural produce stand combination district. (See Policy AG/LU-132.)\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 56, \"end\": 155, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-20.5: New public safety facilities shall be located within existing urbanized (i.e. nonagricultural) areas of the County and the County shall require site-specific analysis of new public safety facilities prior to their construction.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 18, \"end\": 112, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-21: The following standards shall apply to lands designated as Agricultural Resource on the Land Use Map of this General Plan. Intent: To identify areas in the fertile valley and foothill areas of the county in which agriculture is and should continue to be the predominant land use, where uses incompatible with agriculture should be precluded, and where the development of urban type uses would be detrimental to the continuance of agriculture and the maintenance of open space which are economic and aesthetic attributes and assets of the County of Napa. General Uses: Agriculture, processing of agricultural products, single-family dwellings. Minimum Parcel Size: 40 acres, except that parcels with a minimum size of 2 acres may be created for the sole purpose of developing farm labor camps by a local government agency authorized to own or operate farm labor camps, so long as the division is accomplished by securing the written consent of a local government agency authorized to own or operate farm labor camps that it will accept a conveyance of the fee interest of the parcel to be created and thereafter conveying the fee interest of such parcel directly to said local government agency, or entering into a long-term lease of such parcels directly with said local government agency, or entering into a long-term lease of such parcels directly with said local government agency. Every lease or deed creating such parcels must contain language ensuring that if the parcel is not used as a farm labor camp within three years of the conveyance or lease being executed or permanently ceases to be used as a farm labor camp by a local government agency authorized to develop farm labor camps, the parcel will automatically revert to, and merge into, the original parent parcel. Maximum Building Intensity: One dwelling per parcel (except as specified in the Housing Element). Nonresidential building intensity is non-applicable. Pursuant to Measure Z (1996), the sale to the public of agricultural produce, fruits, vegetables, and Christmas trees, grown on or off premises, and items related thereto, as well as the recreation and educational uses by children of animals, such as children’s pony rides and petting zoos, and construction of buildings to accommodate such sales and animals shall be permitted on any parcel designated as agricultural produce stand combination district.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 56, \"end\": 137, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-22: Urban uses shall be concentrated in the incorporated cities and town and designated urbanized areas of the unincorporated County in order to preserve agriculture and open space, encourage transit-oriented development, conserve energy, and provide for healthy, “walkable” communities.\",\n",
        "        \"entities\": [\n",
        "            { \"start\": 50, \"end\": 145, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-23: Consistent with longstanding practice and “smart growth” principles, the County will enact and enforce regulations that will encourage the concentration of residential growth within the County’s existing cities and town and urbanized areas designated on the Land Use Map\",\n",
        "        \"entities\": [\n",
        "            { \"start\": 192, \"end\": 287, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-24: Commercial uses will be grouped in areas outside of those designated for agricultural uses in the General Plan (subject to exceptions contained in Policies AG/LU-43 through 45 of this General Plan).\",\n",
        "        \"entities\": [\n",
        "            { \"start\": 52, \"end\": 127, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-25: The County opposes the creation of new special districts planned to accommodate new residential developments outside existing urbanized areas, except as specified in the Housing Element or as permitted within the Napa Pipe Mixed Use designation.\",\n",
        "        \"entities\": [\n",
        "            { \"start\": 126, \"end\": 158, \"label\": \"LANDUSE\" },\n",
        "            { \"start\": 160, \"end\": 202, \"label\": \"HOUSING\" },\n",
        "            { \"start\": 219, \"end\": 261, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-26: The County will discourage proposed urban developments which require urban services outside of existing urbanized areas. However, nothing in this Agricultural Preservation and Land Use Element is intended to preclude the construction of a single-family residence, on an existing, vacant, legal parcel of land in compliance with adopted County ordinances and other applicable regulations, except on designated park land. Pursuant to State law, small child care centers are considered residential uses. Where maximum dwelling unit densities are specified in this General Plan, the population density is determined by multiplying the allowable number of dwelling units times the average persons per household in the unincorporated County as determined by the most recent U.S. Census\",\n",
        "        \"entities\": [\n",
        "            { \"start\": 101, \"end\": 136, \"label\": \"LANDUSE\" }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"Policy AG/LU-43: Lands along the west bank of the Napa River south of the City of Napa and specific urban areas within four miles of the high water mark of Lake Berryessa are appropriate areas for marine commercial zoning and development. Action Item AG/LU 43.1: Consider amendments to the Zoning Code to allow additional commercial, residential, and mixed uses in the areas currently zoned for commercial use in the Spanish Flat, Moskowite Corners, and southern Pope Creek areas in order to complement recreation activities at Lake Berryessa.\",\n",
        "        \"entities\": [\n",
        "          { \"start\": 30, \"end\": 39, \"label\": \"GEO_FEATURE\" },\n",
        "          { \"start\": 47, \"end\": 57, \"label\": \"GEO_FEATURE\" },\n",
        "          { \"start\": 63, \"end\": 85, \"label\": \"PLACE_SPECIFIC\" },\n",
        "          { \"start\": 110, \"end\": 124, \"label\": \"MEASURE\" },\n",
        "          { \"start\": 132, \"end\": 149, \"label\": \"MEASURE\" },\n",
        "          { \"start\": 153, \"end\": 168, \"label\": \"PLACE_SPECIFIC\" },\n",
        "          { \"start\": 207, \"end\": 234, \"label\": \"ZONING\" },\n",
        "          { \"start\": 286, \"end\": 297, \"label\": \"ZONING\" },\n",
        "          { \"start\": 309, \"end\": 350, \"label\": \"LANDUSE\" },\n",
        "          { \"start\": 397, \"end\": 410, \"label\": \"PLACE_SPECIFIC\" },\n",
        "          { \"start\": 412, \"end\": 431, \"label\": \"PLACE_SPECIFIC\" },\n",
        "          { \"start\": 441, \"end\": 461, \"label\": \"PLACE_SPECIFIC\" },\n",
        "          { \"start\": 540, \"end\": 555, \"label\": \"PLACE_SPECIFIC\" }\n",
        "        ]\n",
        "      }\n",
        "\n",
        "\n",
        "    ]\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOu-lr_tgC30"
      },
      "source": [
        "As you can see we labelled each policy with a corresponding underlined part of the policy with a specific entity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_ZlMNvogzU6"
      },
      "source": [
        "### Implementation Steps?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfpN2oLKhSc0"
      },
      "source": [
        "First, take in JSON dataset, and run through to convert to a spaCy file: `training_data.spacy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xuOadq8fLtE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "from spacy.util import filter_spans\n",
        "\n",
        "# Load your JSON data\n",
        "with open('napagp_training.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Prepare the structure for training data\n",
        "training_data = {'annotations': []}\n",
        "\n",
        "for example in data['training_data']:\n",
        "    temp_dict = {}\n",
        "    temp_dict['text'] = example['text']\n",
        "    temp_dict['entities'] = []\n",
        "\n",
        "    for entity in example['entities']:\n",
        "        start = entity['start']\n",
        "        end = entity['end']\n",
        "        label = entity['label'].upper()\n",
        "        temp_dict['entities'].append((start, end, label))\n",
        "\n",
        "    training_data['annotations'].append(temp_dict)\n",
        "\n",
        "# Load pretrained model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add custom labels to the NER component\n",
        "if \"ner\" not in nlp.pipe_names:\n",
        "    ner = nlp.add_pipe(\"ner\")\n",
        "else:\n",
        "    ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "custom_labels = [\n",
        "    'LANDUSE', 'AGRICULTURE', 'GEO', 'RESIDENTIAL', 'OPEN_SPACE',\n",
        "    'PLANNING_AREA', 'ZONING', 'FACILITY_STATUS', 'MAP_SOURCE',\n",
        "    'HOUSING', 'DIRECTION', 'MEASURE'\n",
        "]\n",
        "\n",
        "for label in custom_labels:\n",
        "    ner.add_label(label)\n",
        "\n",
        "# Convert to spaCy DocBin format\n",
        "doc_bin = DocBin()\n",
        "\n",
        "for training_example in tqdm(training_data['annotations']):\n",
        "    text = training_example['text']\n",
        "    labels = training_example['entities']\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "\n",
        "    for start, end, label in labels:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(f\"Skipping invalid span for text: '{text[start:end]}' (start: {start}, end: {end})\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "\n",
        "    doc.ents = filter_spans(ents)\n",
        "    doc_bin.add(doc)\n",
        "\n",
        "# Save the training data\n",
        "doc_bin.to_disk(\"training_data.spacy\")\n",
        "print(\"Training data saved as training_data.spacy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3slWPtffhbFX"
      },
      "source": [
        "Second, using command line, train a NER model on this new spaCY file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU8XU6Kchom9"
      },
      "outputs": [],
      "source": [
        "!python -m spacy init config config.cfg --lang en --pipeline ner\n",
        "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5KxRntNh5cT"
      },
      "source": [
        "Third, run your model of some of the testing data. Test data is a subset of unseen data to see how well the model does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43hDfB6riD_P"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Load the trained model\n",
        "nlp = spacy.load('output/model-best')  # trained model's directory\n",
        "\n",
        "# List of sample policies to test\n",
        "policies = [\n",
        "    \"Policy AG/LU-120: The County shall work with the school districts serving students in the County to coordinate the provision of school facilities in conjunction with demographic changes and student populations. The County shall also encourage incorporated jurisdictions to reserve school sites within their boundaries.\",\n",
        "    \"Policy AG/LU-121: The County shall coordinate an exchange of information with the school districts regarding school needs and new residential developments in the unincorporated area.\",\n",
        "    \"Policy AG/LU-122: The County shall consider school districts’ proposed school sites in relation to: a) General Plan designations. b) Geology and seismic considerations, topography, drainage, soils. c) Location and general utility of land; population distribution. d) Access, transportation facilities, utilities. e) Conflicting or hazardous conditions (e.g., noise, traffic). f) Protection of agricultural lands. The results of the review are to be forwarded to the appropriate school district board within 30 days from the receipt of the referral.\",\n",
        "    \"Policy AG/LU-123: The County shall establish general school site location criteria such as: a) New school facilities shall not be located within two miles of an airport unless approved by the State Department of Education. b) School facilities shall, whenever practical, be located in areas designated in the appropriate general plan for urban development. c) Coordinate County plans and ordinances to be supportive of school use and to minimize the need for busing students. d) Ensure that proposals for multi-family housing or multiple-lot subdivisions within the unincorporated area are evaluated to determine their impact on schools and are modified to address potential impacts, including the need for new facilities, if any.\",\n",
        "    \"Policy AG/LU-124: New churches or institutions providing religious instruction shall not be located within proximity to an airport, unless they are located in an area where residential uses would be compatible under the applicable Airport Land Use Compatibility Plan. June 23, 2009 Napa County General Plan AG/LU–77\",\n",
        "    \"Policy AG/LU-125: New churches or other religious institutions should generally be located within or adjacent to urbanized areas, minimizing the transportation needs of parishioners/members and the potential for loss of agricultural lands. Action Item AG/LU-125.1: Consider amendments to the Zoning Code that would reduce the number of zoning districts in which new churches and religious institutions may be located and provide siting criteria as part of the use permit process. REGIONAL PLANNING ISSUES\",\n",
        "    \"Policy AG/LU-126: State law charges LAFCO with planning the orderly development of local government agencies to advantageously provide for the present and future needs of the community while protecting against the inappropriate conversion of agricultural and open space lands. A principal planning responsibility of LAFCO is to determine a sphere of influence for each city and special district under its jurisdiction. State law defines a sphere of influence as 'a plan for the probably physical boundaries and service area of a local agency, as determined by' LAFCO. LAFCO is required to review and update, as necessary, each agency’s sphere of influence every five years, and the County will work collaboratively with LAFCO in its reviews of spheres to encourage orderly, city-centered growth and development in Napa County and the preservation of agricultural land. Policy AG/LU-126.5: The County seeks to engage incorporated jurisdictions and other agencies in collaborative planning efforts, particularly efforts aimed at ensuring adequate infrastructure capacity, vibrant city-centers, sufficient housing and agricultural lands and natural resource protection.\",\n",
        "    \"Policy AG/LU-127: The County will coordinate with the cities and town to establish land use policies for unincorporated lands located within their respective spheres of influence and will do likewise for unincorporated lands within any locally-adopted urban growth boundaries.\",\n",
        "    \"Policy AG/LU-128: The County recognizes the urban limit line or Rural Urban Limit (RUL) established for the City of Napa (See Figure LU-4), and agrees that unincorporated land located within the RUL will not be further urbanized without annexation to the City. For purposes of this policy only, engaging in uses that are permitted in the applicable zoning district without the issuance of a use permit shall not be considered urbanizing. In all cases, subdividing property shall be deemed urbanizing for purposes of this policy.\"\n",
        "]\n",
        "\n",
        "# Process and visualize each policy\n",
        "for policy in policies:\n",
        "    print(f\"Visualizing: {policy[:60]}...\")  # Show part of the policy text for reference\n",
        "    doc = nlp(policy)\n",
        "\n",
        "    # Visualize the named entities\n",
        "    displacy.render(doc, style='ent', page=True)\n",
        "    print(\"-\" * 50)  # Separator between policies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1P9tDbPiOtn"
      },
      "source": [
        "Here we will be able to visualize the results of what entities were captured."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2vpw6W0ELpn"
      },
      "source": [
        "# flair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WUPul_KJOCj"
      },
      "source": [
        "The code below will install flair, the NER package we will be working with. It might take a while to run. This is completely normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ5zpe5fTWw-",
        "outputId": "02dbb418-0b3f-48a7-f966-c558d954e01c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.26.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
            "Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.11/dist-packages (from flair) (1.38.30)\n",
            "Requirement already satisfied: conllu<5.0.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from flair) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from flair) (1.2.18)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from flair) (6.3.1)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from flair) (0.32.2)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.11/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.4.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from flair) (3.10.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.11/dist-packages (from flair) (10.7.0)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.11/dist-packages (from flair) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.11/dist-packages (from flair) (3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from flair) (2.9.0.post0)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from flair) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from flair) (1.6.1)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.11/dist-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from flair) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from flair) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from flair) (4.67.1)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from flair) (0.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.26.1)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from flair) (0.8.1)\n",
            "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from flair) (2.1)\n",
            "Requirement already satisfied: jsonlines>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (4.0.0)\n",
            "Requirement already satisfied: intervaltree in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (0.6.2)\n",
            "Requirement already satisfied: botocore<1.39.0,>=1.38.30 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (1.38.30)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (0.13.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->flair) (1.17.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (1.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect>=1.0.9->flair) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.24.4)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (3.2.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mpld3>=0.3->flair) (3.1.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->flair) (1.3.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.13.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (3.20.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.39.0,>=1.38.30->boto3>=1.20.27->flair) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (25.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.7)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install flair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56O-NlYWJ0xQ"
      },
      "source": [
        "This code will import the modules we will be working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "4xMXDCzdBQn0",
        "outputId": "4983102f-4014-4675-9afc-e04583059829"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'dtypes'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-24f08684a417>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf_set_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# global variable: cache_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tokenizers\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# must be loaded here, or else tqdm check may fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m \u001b[0;31m# line: 125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m \u001b[0;31m# line: 125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpsSet\u001b[0m \u001b[0;31m# line: 170\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtoco_convert\u001b[0m \u001b[0;31m# line: 1083\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauthoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelAnalyzer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAnalyzer\u001b[0m \u001b[0;31m# line: 35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpResolverType\u001b[0m \u001b[0;31m# line: 303\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthoring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthoring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatible\u001b[0m \u001b[0;31m# line: 263\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_wrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/authoring/authoring.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconverter_error_data_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstablehlo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantization_options_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mquant_opts_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite_constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_phase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_phase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0m_jit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# See PEP 484 & https://github.com/jax-ml/jax/issues/7570\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from jax._src.core import (\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mAbstractToken\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAbstractToken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mAbstractValue\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAbstractValue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;31m# StringDType to be used in there.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0m_string_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJAXType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'StringDType'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mxla_extension_version\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m311\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m   \u001b[0m_string_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJAXType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringDType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    321\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'dtypes'"
          ]
        }
      ],
      "source": [
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "yZmKlFdrTeI9",
        "outputId": "619532aa-ccbf-45b0-c7fa-b9fd553fb0ef"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'requires_backends' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2e6d4c40c1cf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mner_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SequenceTagger\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/nn/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/nn/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_torch_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mload_torch_state\u001b[0;34m(model_file)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# see https://github.com/zalandoresearch/flair/issues/351\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_big_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m                 return _load(\n\u001b[0m\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0m_arrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" → \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m from . import (  # noqa: E402 import after setting device\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/trainers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlanguage_model_trainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLanguageModelTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextCorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ModelTrainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LanguageModelTrainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TextCorpus\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_main_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_corpus_same_each_process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlairSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m from flair.trainers.plugins import (\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mAnnealingPlugin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mCheckpointPlugin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/trainers/plugins/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepncm_trainer_plugin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepNCMPlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSchedulerPlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_transformer_vocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReduceTransformerVocabPlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_extractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWeightExtractorPlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclearml_logger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClearmlLoggerPlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flair/trainers/plugins/functional/reduce_transformer_vocab.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformer_smaller_training_vocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduce_train_vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStackedEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformer_smaller_training_vocab/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreduce_train_vocab_and_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformer_smaller_training_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_texts_from_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"get_texts_from_dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recreate_vocab\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reduce_train_vocab\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reduce_train_vocab_and_context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformer_smaller_training_vocab/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_datasets_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTokenizedInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTokenizedInputPair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextInputPair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'requires_backends' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "ner_model = SequenceTagger.load('ner')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I1PLYSSSxi6"
      },
      "source": [
        "Assuming we already have a csv file of extracted policies, next we will iterate through each one and identify the spatial terms in each one. This function takes the text of each policy, tokenizes the text into individual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0CGXG0gS58V"
      },
      "outputs": [],
      "source": [
        "def add_to_csv(filename, nlp_column, new_column_name, output_filename=None):\n",
        "    dataframe = pd.read_csv(filename)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for _, row in dataframe.iterrows():\n",
        "        text = row[nlp_column]\n",
        "        sentence = Sentence(str(text))\n",
        "        ner_model.predict(sentence)\n",
        "        entities = sentence.get_spans('ner')\n",
        "        results.append(entities)\n",
        "\n",
        "    dataframe[new_column_name] = results\n",
        "\n",
        "    if output_filename is None:\n",
        "        output_filename = filename\n",
        "    dataframe.to_csv(output_filename, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt5WMY0NVAM7"
      },
      "source": [
        "Next, we will call the function we developed in the previous section. You will first have to upload the spreadsheet you are working with by clicking the file upload button on the left of your screen and then selecting the file from your local drive. Once that upload is done, you will then right click the file and select \"Copy Path.\" This file path will go in place of the one currently being stored in the hazard_plan_csv variable, and the variable should be renamed accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "dwt8sCYFT1AI",
        "outputId": "10ebe16c-3beb-4a76-f22a-105aada88a3c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ner_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-869adcd53ade>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"napa_hazard_plan_tables_with_flair.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcsv_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0madd_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhazard_plan_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Description\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Entities\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"New column added.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3fd13a0bf6c4>\u001b[0m in \u001b[0;36madd_to_csv\u001b[0;34m(filename, nlp_column, new_column_name, output_filename)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnlp_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mner_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ner_model' is not defined"
          ]
        }
      ],
      "source": [
        "hazard_plan_csv = \"/content/Napa Hazard Plan NER.csv\"\n",
        "file = \"napa_hazard_plan_tables_with_flair.csv\"\n",
        "csv_filename = '/content/drive/MyDrive/' + file\n",
        "add_to_csv(hazard_plan_csv, \"Description\", \"Entities\", csv_filename)\n",
        "print(\"New column added.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZazXNed_JFlG",
        "outputId": "26b351a3-7f68-4b8e-d4f1-e70dfbf21ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping flair as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pandas as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: numpy 1.24.4\n",
            "Uninstalling numpy-1.24.4:\n",
            "  Successfully uninstalled numpy-1.24.4\n",
            "Collecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "db-dtypes 1.4.3 requires pandas>=1.5.3, which is not installed.\n",
            "shap 0.47.2 requires pandas, which is not installed.\n",
            "mlxtend 0.23.4 requires pandas>=0.24.2, which is not installed.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires pandas>=1.1.4, which is not installed.\n",
            "statsmodels 0.14.4 requires pandas!=2.1.0,>=1.4, which is not installed.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, which is not installed.\n",
            "bigquery-magics 0.9.0 requires pandas>=1.1.0, which is not installed.\n",
            "gradio 5.31.0 requires pandas<3.0,>=1.0, which is not installed.\n",
            "datasets 2.14.4 requires pandas, which is not installed.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, which is not installed.\n",
            "cufflinks 0.17.3 requires pandas>=0.19.2, which is not installed.\n",
            "bigframes 2.4.0 requires pandas>=1.5.3, which is not installed.\n",
            "pandas-gbq 0.29.0 requires pandas>=1.1.4, which is not installed.\n",
            "peft 0.15.2 requires transformers, which is not installed.\n",
            "datascience 0.17.6 requires pandas, which is not installed.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, which is not installed.\n",
            "yfinance 0.2.61 requires pandas>=1.3.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires pandas>=0.24.2, which is not installed.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, which is not installed.\n",
            "xarray 2025.3.1 requires pandas>=2.1, which is not installed.\n",
            "bokeh 3.7.3 requires pandas>=1.2, which is not installed.\n",
            "tsfresh 0.21.0 requires pandas>=0.25.0, which is not installed.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\n",
            "fastai 2.7.19 requires pandas, which is not installed.\n",
            "prophet 1.1.6 requires pandas>=1.0.4, which is not installed.\n",
            "seaborn 0.13.2 requires pandas>=1.2, which is not installed.\n",
            "cmdstanpy 1.2.5 requires pandas, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires pandas, which is not installed.\n",
            "dask-cuda 25.2.0 requires pandas>=1.3, which is not installed.\n",
            "holoviews 1.20.2 requires pandas>=1.3, which is not installed.\n",
            "geemap 0.35.3 requires pandas, which is not installed.\n",
            "libpysal 4.13.0 requires pandas>=1.4, which is not installed.\n",
            "arviz 0.21.0 requires pandas>=1.5.0, which is not installed.\n",
            "bqplot 0.12.45 requires pandas<3.0.0,>=1.0.0, which is not installed.\n",
            "pymc 5.23.0 requires pandas>=0.24.0, which is not installed.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.3.4 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.0 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "9896cde8ab844a8887df1425fc6171ca",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.26.1\n",
            "  Using cached transformers-4.26.1-py3-none-any.whl.metadata (100 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.26.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.26.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.26.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.26.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.26.1) (2025.4.26)\n",
            "Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "Installing collected packages: transformers\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mException ignored in: <function _get_module_lock.<locals>.cb at 0x7b51ab8cac00>\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 207, in cb\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 78, in main\n",
            "    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n",
            "    module = importlib.import_module(module_path)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 15, in <module>\n",
            "    from pip._internal.cli.req_command import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 19, in <module>\n",
            "    from pip._internal.index.package_finder import PackageFinder\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/package_finder.py\", line 31, in <module>\n",
            "    from pip._internal.req import InstallRequirement\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/__init__.py\", line 9, in <module>\n",
            "    from .req_install import InstallRequirement\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 41, in <module>\n",
            "    from pip._internal.pyproject import load_pyproject_toml, make_pyproject_path\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/pyproject.py\", line 6, in <module>\n",
            "    from pip._vendor import tomli\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/tomli/__init__.py\", line 8, in <module>\n",
            "    from ._parser import TOMLDecodeError, load, loads\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 701, in _load_unlocked\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting pandas==2.0.3\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2025.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (1.24.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.17.0)\n",
            "Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.0.3\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'flair'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9ad2c7994026>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flair'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y transformers flair pandas numpy\n",
        "\n",
        "!pip install numpy==1.24.4\n",
        "\n",
        "!pip install transformers==4.26.1\n",
        "!pip install flair==0.12.2\n",
        "!pip install pandas==2.0.3\n",
        "\n",
        "import pandas as pd\n",
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence\n",
        "\n",
        "ner_model = SequenceTagger.load('ner')\n",
        "\n",
        "def add_to_csv(filename, nlp_column, new_column_name, output_filename=None):\n",
        "    dataframe = pd.read_csv(filename)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for _, row in dataframe.iterrows():\n",
        "        text = row[nlp_column]\n",
        "        sentence = Sentence(str(text))\n",
        "        ner_model.predict(sentence)\n",
        "        entities = sentence.get_spans('ner')\n",
        "        results.append(entities)\n",
        "\n",
        "    dataframe[new_column_name] = results\n",
        "\n",
        "    if output_filename is None:\n",
        "        output_filename = filename\n",
        "    dataframe.to_csv(output_filename, index=False)\n",
        "\n",
        "\n",
        "hazard_plan_csv = \"/content/Napa Hazard Plan NER.csv\"\n",
        "file = \"napa_hazard_plan_tables_with_flair.csv\"\n",
        "csv_filename = '/content/drive/MyDrive/' + file\n",
        "add_to_csv(hazard_plan_csv, \"Description\", \"Entities\", csv_filename)\n",
        "print(\"New column added.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg2npK13hKjQ"
      },
      "source": [
        "# Integration & Future Work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjamIjiAZvpG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIPCzFojhNwd"
      },
      "source": [
        "We have started working with the Gemini AI model, which has shown promising results. It has been able to fully identify nuanced or context-dependent spatial terms. The model performs well out of the box, and we’re currently exploring how its capabilities can complement our custom NER system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXOcqJYfqVg6"
      },
      "source": [
        "** Reference how to create and run the Gemini AI model from the LLM Documentation.\n",
        "\n",
        "Replace the prompt with a new prompt specifying to extract specific types of spatial terms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etKmImcTq8F9"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "    Extract the following types of spatial (mappable) terms from the policy text:\n",
        "    1. Place names (either general, like \"downtown\", or specific, like \"Angwin\").\n",
        "    2. Land use or zoning classifications.\n",
        "    3. Geographical features (e.g., creeks, mountains, rivers).\n",
        "    4. Structures, including facilities, buildings, and infrastructure.\n",
        "    5. Mappable units of measure (e.g., distances, areas such as acres, hectares, square miles, parcels, buffers).\n",
        "    6. Geospatial terms (e.g., raster, point, polygon, line, or file types such as GeoJSON, .shp, etc.).\n",
        "    The response should be a comma-separated list of these terms from the following policy text:\\n\\n{policy_text}\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0rakwI5p_dm"
      },
      "source": [
        "### Future Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLzsq-rRrFd8"
      },
      "source": [
        "**Model Ensembling:** Combine the strengths of our custom NER and Gemini through ensembling techniques. This hybrid approach aims to boost accuracy and handle more complex or ambiguous spatial terms.\n",
        "\n",
        "**Expanded Entity Set & Dataset:** Continue expanding the entity taxonomy to cover additional planning domains, such as fire, land use, safety element, etc. At the same time, grow and diversify the labeled policy dataset by including the rest of the policies from other plans (maybe?).\n",
        "\n",
        "**Text-to-GIS Mapping:** Develop a pipeline to connect extracted spatial entities directly to geographic features. This involves:\n",
        "* Mapping NER outputs to GIS layers (e.g., zoning districts, land use boundaries)\n",
        "* Implementing geocoding for named places and address-based entities\n",
        "* Exploring spatial ontologies or standardized vocabularies to support reliable mapping.\n",
        "\n",
        "Ultimately, the goal is to enable workflows that move from policy text → structured entities → mapped outputs, unlocking powerful new capabilities for planning and analysis."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "P_zCi6FId0Hw",
        "bo_HGX_ueXiS",
        "fElvGDV0ehPC",
        "iBLbHnq7fBu-",
        "0SRGxBqcfffX",
        "h_ZlMNvogzU6",
        "I0rakwI5p_dm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
